{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ChungkiLee\\Documents\\GitHub\\webcam\n",
      "The frame rate is: 30\n"
     ]
    }
   ],
   "source": [
    "# 측정하는 cell\n",
    "%reset\n",
    "%cd C:\\Users\\ChungkiLee\\Documents\\GitHub\\webcam\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import datetime\n",
    "import sys\n",
    "import time\n",
    "import pylab\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import shelve\n",
    "# from imutils import face_utils\n",
    "# import imutils\n",
    "# import dlib\n",
    "\n",
    "def convertToRGB(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def valueToExtract(img):\n",
    "    \n",
    "    b, g, r = cv2.split(img)\n",
    "    tmp2 = np.mean(r)\n",
    "    tmp3 = np.mean(g)\n",
    "    tmp4 = np.mean(b)\n",
    "    return tmp2, tmp3, tmp4\n",
    "\n",
    "def column(matrix, i):\n",
    "    return [row[i] for row in matrix]\n",
    "\n",
    "def resource_path(relative_path):\n",
    "    \"\"\" Get absolute path to resource, works for dev and for PyInstaller \"\"\"\n",
    "    try:\n",
    "        # PyInstaller creates a temp folder and stores path in _MEIPASS\n",
    "        base_path = sys._MEIPASS\n",
    "    except Exception:\n",
    "        base_path = os.path.abspath(\".\")\n",
    "\n",
    "    return os.path.join(base_path, relative_path)\n",
    "\n",
    "def get_subface_coord(face_rect, fh_x, fh_y, fh_w, fh_h):\n",
    "    x, y, w, h = face_rect\n",
    "    return [int(x + w * fh_x - (w * fh_w / 2.0)),\n",
    "            int(y + h * fh_y - (h * fh_h / 2.0)),\n",
    "            int(w * fh_w),\n",
    "            int(h * fh_h)]\n",
    "\n",
    "def preset_img_size(face_rect, wn):\n",
    "    x, y, w, h = face_rect[0]\n",
    "    w = wn\n",
    "    \n",
    "    h = int(w*1.1);\n",
    "    faces_tmp = [[x, y, w, h]]\n",
    "    return faces_tmp\n",
    "\n",
    "\n",
    "# Create a VideoCapture object\n",
    "cap = cv2.VideoCapture(0)\n",
    "frameRate = 30.0\n",
    "cap.set(cv2.CAP_PROP_FPS, frameRate)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720) # 720, 1080\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280) # 1280, 1980\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "print(\"The frame rate is: \" + str(fps))\n",
    "\n",
    "dpath = resource_path('haarcascade_frontalface_alt.xml') #'haarcascade_frontalface_default.xml', 'haarcascade_frontalface_alt.xml'\n",
    "face_cascade = cv2.CascadeClassifier(dpath)\n",
    "\n",
    "# Check if camera opened successfully\n",
    "if (cap.isOpened() == False): \n",
    "    print(\"Unable to read camera feed\")\n",
    "\n",
    "# Default resolutions of the frame are obtained.The default resolutions are system dependent.\n",
    "# We convert the resolutions from float to integer.\n",
    "frame_width  = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "\n",
    "# Define the codec and create VideoWriter object.The output is stored in 'outpy.avi' file.\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID') # XVID\n",
    "tmp1 = str(datetime.datetime.now())\n",
    "tmp1 = tmp1.replace(\":\", \"_\").replace(\".\", \"_\").replace(\" \", \"_\").replace(\"-\", \"_\")\n",
    "tmp2 = 'C:/Users/ChungkiLee/Documents/GitHub/webcam/previewimgs/outpy'\n",
    "tmp3 = tmp2 + tmp1[:19] +'.mp4'\n",
    "tmp4 = tmp2 + tmp1[:19] +'.out'\n",
    "out = cv2.VideoWriter(tmp3, fourcc, frameRate, (frame_width,frame_height))\n",
    "filename = tmp4\n",
    "del(tmp1, tmp2, tmp3, tmp4)\n",
    "\n",
    "imageEndingSeconds = 10;\n",
    "mg = 10; sig_y = []; sig_x =[];\n",
    "shooting = 'N'\n",
    "cnt = 0\n",
    "a= 0.0; b=0.0; c= 0.0;\n",
    "sig_x = [] ; sig_y = [];\n",
    "faces = [];\n",
    "faces_tmp = [[0, 0, 0, 0]];\n",
    "imgs = [];\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "#     ret = ret.set(cv2.CAP_PROP_FPS, frameRate)\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    if ret == True: \n",
    "        \n",
    "        # 이것은 image 데이터를 저장하는 곳\n",
    "        if cnt > 90:\n",
    "            shooting = 'Y'\n",
    "            cv2.putText(frame, \"image number: %s\" % str(cnt-90), (10, 25), cv2.FONT_HERSHEY_PLAIN, 2, (100, 255, 100))\n",
    "            cv2.putText(frame, \"recording time(sec): %s\" % str((c*1000//2)/500), (10, 50), cv2.FONT_HERSHEY_PLAIN, 2, (100, 255, 100))\n",
    "        else: \n",
    "            cv2.putText(frame, \"Ready to the 90th frame: %s\" % str(cnt), (10, 25), cv2.FONT_HERSHEY_PLAIN, 2, (100, 255, 100))\n",
    "            cv2.putText(frame, \"recording time(sec): %s\" % str((c*1000//2)/500), (10, 50), cv2.FONT_HERSHEY_PLAIN, 2, (100, 255, 100))\n",
    "            \n",
    "        if shooting == 'Y':\n",
    "\n",
    "            (dt, micro) = datetime.datetime.now().strftime('%Y%m%d%H%M%S.%f').split('.')\n",
    "            b = float(dt) + float(micro)/1000000\n",
    "            c = b - a\n",
    "            # 얼굴영역 처리하는 곳\n",
    "            for (x,y,w,h) in faces:\n",
    "                cv2.rectangle(frame,(x-mg-2,y-mg-2),(x+w+mg+1,y+h+mg+1),(0,255,0),2)\n",
    "                roi_gray = gray[y:y+h, x:x+w]\n",
    "                roi_color = frame[y-mg:y+h+mg, x-mg:x+w+mg]\n",
    "                common_color = frame\n",
    "                red,green,blue = valueToExtract(roi_color)\n",
    "                redC,greenC,blueC = valueToExtract(common_color)\n",
    "                imgs.append(roi_color)\n",
    "                sig_y.append([red,green,blue,redC,greenC,blueC])\n",
    "                sig_x.append(c)\n",
    "            # 신호처리하는 곳\n",
    "            if len(sig_x) > 3:\n",
    "                x = np.array(sig_x)\n",
    "                y = -(np.array(sig_y)[:, 1])\n",
    "#                 y = -(np.array(sig_y)[:, 1]/(np.array(sig_y)[:, 4] - np.array(sig_y)[:, 1]))\n",
    "                xx = (frame_width)*(x - x.min()) / (imageEndingSeconds - x.min())\n",
    "                yy = (frame_height/7)*(y - y.min()) / (y.max() - y.min())+frame_height*1/6\n",
    "                pts = np.array([[x_, y_] for x_, y_ in zip(xx,yy)], np.int32)\n",
    "                frame = cv2.polylines(frame,[pts[:cnt-90]],False,(0,255,255), 2)\n",
    "            # Write the frame into the file 'output.avi'\n",
    "            out.write(frame)            \n",
    "            if c > imageEndingSeconds:\n",
    "                break\n",
    "            cnt += 1\n",
    "        else:\n",
    "            # 얼굴 인식 하는곳\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            k = 31\n",
    "            gray = cv2.GaussianBlur(gray, (k, k), 0)\n",
    "#             gray = cv2.equalizeHist(gray)   \n",
    "            gray = cv2.pyrDown( gray )\n",
    "            gray = cv2.pyrDown( gray )\n",
    "            faces = face_cascade.detectMultiScale(gray, 1.3, 3, flags = cv2.CASCADE_SCALE_IMAGE)\n",
    "            faces = faces * 4\n",
    "            if len(faces) == 1:\n",
    "                faces_tmp = (faces_tmp + faces)//2\n",
    "#                 print(faces_tmp[0][2])\n",
    "                faces2 = preset_img_size(faces_tmp, int(faces_tmp[0][2]*1.1))\n",
    "                faces = np.array(faces2)\n",
    "            \n",
    "            for (x,y,w,h) in faces:\n",
    "                cv2.rectangle(frame,(x-mg-2,y-mg-2),(x+w+mg+1,y+h+mg+1),(0,255,0),2)\n",
    "            \n",
    "            (dt, micro) = datetime.datetime.now().strftime('%Y%m%d%H%M%S.%f').split('.')\n",
    "            a = float(dt) + float(micro)/1000000\n",
    "            cnt += 1\n",
    "            \n",
    "        # Display the resulting frame    \n",
    "        cv2.imshow('frame',frame)\n",
    "        \n",
    "        # Press Q on keyboard to stop recording\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    # Break the loop\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# When everything done, release the video capture and video write objects\n",
    "cap.release()\n",
    "out.release()\n",
    " \n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "my_shelf = shelve.open(filename, 'n')\n",
    "saving_files = ['imgs', 'sig_x', 'sig_y']\n",
    "for key in saving_files:\n",
    "    try:\n",
    "        my_shelf[key] = globals()[key]\n",
    "    except TypeError:\n",
    "        print('error shelvinf : {0}'.format(key))\n",
    "my_shelf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
